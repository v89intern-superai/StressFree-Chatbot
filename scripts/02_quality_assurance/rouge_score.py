# -*- coding: utf-8 -*-
"""
Recalculate ROUGE Score Script (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Google Colab)

‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå qa_results.csv
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö

‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Google Colab:
1. ‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ô‡∏µ‡πâ
2. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
3. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏∏‡πà‡∏° "Choose Files" ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `qa_results.csv`
4. ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
"""

# ==============================================================================
# 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞ Import Libraries
# ==============================================================================
print("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô...")
# !pip install -q -U pythainlp
print("‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

import pandas as pd
import sys
import os
from pythainlp.tokenize import word_tokenize
from collections import Counter
from difflib import SequenceMatcher

# --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏±‡∏ô‡πÉ‡∏ô Google Colab ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ---
IN_COLAB = 'google.colab' in sys.modules

# ==============================================================================
# 2. Configuration & File Upload
# ==============================================================================
QA_RESULTS_FILE = None

if IN_COLAB:
    from google.colab import files
    print("\nüìÇ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `qa_results.csv` ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:")
    uploaded = files.upload()

    if not uploaded:
        sys.exit("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    QA_RESULTS_FILE = next(iter(uploaded))
    print(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `{QA_RESULTS_FILE}` ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
else:
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö Local, ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Directory ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    QA_RESULTS_FILE = "qa_results.csv"
    if not os.path.exists(QA_RESULTS_FILE):
        sys.exit(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {QA_RESULTS_FILE} ‡πÉ‡∏ô Directory ‡∏ô‡∏µ‡πâ!")

# ==============================================================================
# 3. (CORE LOGIC) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ROUGE ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏≠‡∏á
# ==============================================================================

def _get_ngrams(n, text_tokens):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á n-grams ‡∏à‡∏≤‡∏Å‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏Ç‡∏≠‡∏á tokens"""
    return Counter(tuple(text_tokens[i:i+n]) for i in range(len(text_tokens) - n + 1))

def _calculate_f1(precision, recall):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì F1-Score"""
    if precision + recall == 0:
        return 0.0
    return 2 * (precision * recall) / (precision + recall)

def calculate_rouge_n(reference_tokens, generated_tokens, n):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-N (N=1, 2, ...)"""
    ref_ngrams = _get_ngrams(n, reference_tokens)
    gen_ngrams = _get_ngrams(n, generated_tokens)

    overlapping_ngrams = ref_ngrams & gen_ngrams
    overlapping_count = sum(overlapping_ngrams.values())

    ref_total = sum(ref_ngrams.values())
    gen_total = sum(gen_ngrams.values())

    precision = overlapping_count / gen_total if gen_total > 0 else 0.0
    recall = overlapping_count / ref_total if ref_total > 0 else 0.0
    f1 = _calculate_f1(precision, recall)

    return f1

def calculate_rouge_l(reference_tokens, generated_tokens):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-L (Longest Common Subsequence)"""
    matcher = SequenceMatcher(None, reference_tokens, generated_tokens)
    lcs_length = matcher.find_longest_match(0, len(reference_tokens), 0, len(generated_tokens)).size

    ref_total = len(reference_tokens)
    gen_total = len(generated_tokens)

    precision = lcs_length / gen_total if gen_total > 0 else 0.0
    recall = lcs_length / ref_total if ref_total > 0 else 0.0
    f1 = _calculate_f1(precision, recall)

    return f1


# ==============================================================================
# 4. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV
# ==============================================================================
def process_qa_results(file_path):
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV, ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á, ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
    """
    print(f"\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {file_path}...")
    try:
        df = pd.read_csv(file_path)
        if 'reference_answer' not in df.columns or 'generated_answer' not in df.columns:
            sys.exit("‚ùå ‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'reference_answer' ‡πÅ‡∏•‡∏∞ 'generated_answer'")
    except Exception as e:
        sys.exit(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV: {e}")

    results = []
    print("\n=============================================")
    print("üìä      ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE...      üìä")
    print("=============================================\n")

    for index, row in df.iterrows():
        reference = str(row['reference_answer'])
        generated = str(row['generated_answer'])
        case_id = row.get('id', index + 1)

        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ pythainlp
        ref_tokens = word_tokenize(reference, engine="newmm")
        gen_tokens = word_tokenize(generated, engine="newmm")

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏≠‡∏á
        rouge1 = calculate_rouge_n(ref_tokens, gen_tokens, 1)
        rouge2 = calculate_rouge_n(ref_tokens, gen_tokens, 2)
        rougeL = calculate_rouge_l(ref_tokens, gen_tokens)

        processed_scores = {
            'rouge1': rouge1,
            'rouge2': rouge2,
            'rougeL': rougeL
        }
        results.append(processed_scores)

        print(f"--- ‡πÄ‡∏Ñ‡∏™ #{case_id} ---")
        print(f"  - ROUGE-1: {processed_scores['rouge1']:.4f}")
        print(f"  - ROUGE-2: {processed_scores['rouge2']:.4f}")
        print(f"  - ROUGE-L: {processed_scores['rougeL']:.4f}")
        print("-" * 20)



    # --- ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ ---
    if results:
        avg_df = pd.DataFrame(results)
        avg_scores = avg_df.mean()

        print("\n=============================================")
        print("üìà         ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ROUGE ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢         üìà")
        print("=============================================")
        print(f"  - Average ROUGE-1: {avg_scores['rouge1']:.4f}")
        print(f"  - Average ROUGE-2: {avg_scores['rouge2']:.4f}")
        print(f"  - Average ROUGE-L: {avg_scores['rougeL']:.4f}")
        print("=============================================\n")
    else:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")


if __name__ == "__main__":
    process_qa_results(QA_RESULTS_FILE)
